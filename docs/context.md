
This document supplements the SDLC by providing practical guidance, clarifications, and examples to help teams understand and apply the framework in real terms. It bridges policy and practice—covering common questions, helpful tips, and emerging approaches across all stages of delivery.

---


# **Compliance in Agile: Transitioning from Waterfall to Iterative Methods**

Many of the Department’s current compliance controls were originally designed to support **Waterfall-style projects**—where large, sequential stages lead to a final release.
As we evolve towards **Agile**, **Spiral**, and **Product Operating Models**, our goal is not to discard compliance but to **adapt** it—making assurance activities **lighter, continuous, and embedded** into everyday delivery.

The Department is progressively modernising these artefacts to align with iterative development, automation, and contemporary DevSecOps practices.
Where possible, traditional deliverables should be met through **incremental evidence** produced naturally during sprints, releases, and continuous integration.


## **1. Information Security Assessment (ISA)**

**Purpose:** Ensures information assets are appropriately managed for security, privacy, and classification.
**Legacy expectation:** Conducted once prior to production release.
**Iterative alignment:**

* Embed security and privacy reviews **throughout delivery** rather than waiting for end-stage assessment.
* Perform a **Privacy Threshold Assessment (PTA)** early to determine if a full ISA is needed.
* Track risks and mitigations within each sprint’s backlog or Azure DevOps board.
  **Modernisation direction:** Move toward **automated security scanning**, **reusable patterns**, and **lightweight reassessment** triggered only by major changes in data sensitivity or architecture.


## **2. Cloud Assessment Report (CAR)**

**Purpose:** Confirms compliance for cloud-hosted components.
**Legacy expectation:** Manual report reviewed by Architecture and Security prior to deployment.
**Iterative alignment:**

* Use **approved Azure Landing Zones** and reference **standard deployment templates** to satisfy cloud compliance.
* For new or non-standard patterns, seek **GBN approval** early (particularly where data sovereignty or offshore storage is involved).
  **Modernisation direction:** Integrate CAR validation into **Infrastructure-as-Code pipelines** and **architecture review gates**.


## **3. Release Risk & Issue Register**

SDLC Type 1 projects are typically constrained and follow a waterfall methodology.

To foster a more modern approach, such as those contained in Agile, Spiral or Product Operating Model for release management in SDLC Type 1 projects, consider implementing the following as components:

### Embrace iterative development

  * Break down the project into smaller, manageable increments. This allows for regular feedback and adjustments, rather than waiting until the end of the project to  assess progress.

### Incorporate Agile practices

  * Integrate Agile methodologies, such as Scrum or Kanban, into the release management process. This can involve daily stand-ups, sprint planning, and retrospectives to foster collaboration and continuous improvement.

### Enhance collaboration

  * Encourage cross-functional team collaboration, ensuring that all stakeholders (developers, testers, project managers) are involved in the planning and execution phases. This helps in identifying issues early and allows for quicker resolution.

### Implement continuous integration and delivery (CI/CD)

  * Adopt CI/CD practices to automate testing and deployment processes. This reduces manual errors and accelerates the release cycle, enabling more frequent updates and faster delivery of features.

### Use feature toggles

  * Implement feature toggles to allow incomplete features to be merged into the main codebase without affecting production. This enables teams to work on multiple features simultaneously while maintaining system stability.

### Use only synthetic data
  * Only use synthetic data that does not identify with any real world people or places. As a starting point to achieve this, you could use data generated by the DevPortal DataForge facility.

### Use mock APIs

  * DevPortal has numerous mock APIs that match the input interfaces and output data types of production grade APIs. You can find these via the APIs menu on the DevPortal home page.

### Focus on documentation and traceability

  * Maintain clear documentation and version control throughout the development process. This ensures that all changes are tracked and can be easily reviewed, facilitating smoother transitions between phases.

### Regularly review and adapt

  * Conduct regular reviews of the development process to identify bottlenecks and areas for improvement. Adapt the approach based on feedback from the team and stakeholders to ensure that the process remains efficient and effective.

By incorporating these strategies, Type 1 projects can benefit from a more agile approach to release management while still adhering to the necessary constraints of the waterfall model. This balance can lead to improved delivery timelines and increased stakeholder satisfaction.

These strategies align with the principles of the Software Development Life Cycle (SDLC) and aim to enhance the overall quality and efficiency of the development process.

**Old Content**

**Purpose:** Documents and manages risks throughout the project lifecycle.
**Legacy expectation:** Maintained as a static document.
**Iterative alignment:**
* Treat risk and issue management as a **living process**—tracked within sprint boards, retrospectives, and product dashboards.
* Encourage teams to identify, mitigate, and close risks continuously rather than at the end of the release.
  **Modernisation direction:** Link risk artefacts directly to **work items**, **user stories**, and **automated test coverage reports** for traceability.



## **4. Acceptance Test Summary Report (ATSR)**

**Purpose:** Demonstrates that functionality meets user and business requirements.
**Legacy expectation:** Formal report completed after testing phase.
**Iterative alignment:**

* Replace standalone reports with **continuous test evidence**—Azure DevOps test plans, automated regression logs, or sprint review outcomes.
* Consider the **Definition of Done (DoD)** as the natural home for acceptance criteria.
  **Modernisation direction:** Encourage **automated test pipelines** and dashboards as proof of compliance.



## **5. Quality Assurance Certificates**

**Purpose:** Validates that software meets Departmental standards for quality, accessibility, and usability.
**Legacy expectation:** Certificates provided at the end of the development cycle.
**Iterative alignment:**

* Incorporate QA activities directly into each sprint’s DoD.
* Use **automated linting and accessibility tools** to support WCAG 2.x and Common User Environment (CUE) compliance.
* Apply **branding and UX checks** as part of design review gates.
  **Modernisation direction:** Move from static sign-offs to **continuous compliance evidence** across sprints.



## **6. Production Readiness Certificate (PRC)**

**Purpose:** Verifies that a product or service is ready for production deployment.
**Legacy expectation:** Large, end-of-project artefact required before go-live.
**Iterative alignment:**

* For **existing products** or **incremental features**, only new or high-risk components should require a PRC.
* For **new products**, perform a full PRC once, then manage ongoing readiness through automated checks.
  **Modernisation direction:** Transition toward **Certificate Tickets (CTs)**—lightweight, risk-based approvals that can be tracked per feature or change.


## **7. Change Management**

**Purpose:** Controls how updates are deployed into production environments.
**Legacy expectation:** Manual approval process focused on major releases.
**Iterative alignment:**

* The Department is reviewing its change management approach to support **Agile and CI/CD** pipelines.
* The intent is to enable **seamless, low-risk delivery** using automated testing, peer reviews, and environment gates.
  **Modernisation direction:** Shift from “change approval” to **change visibility and assurance**, supported by telemetry, audit trails, and release automation.


### **Summary**

The overarching principle is **continuous compliance**—building quality and assurance into every step of delivery, rather than applying it as a final gate.
Each traditional artefact should evolve from a **document** into an **automated, iterative control**, aligned with real-time feedback and observable evidence from modern development tools.

---
