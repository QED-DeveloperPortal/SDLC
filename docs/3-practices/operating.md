## Operating
*Keeping systems reliable, observable, and ready to grow.*
* Ensures the product performs under real-world conditions
* Monitors usage, availability, and issues to drive proactive action
* Keeps services safe, compliant, and up to date
* Builds in learning loops and operational visibility—not just support tickets
* Sets the stage for continuous evolution, not quiet abandonment


### Desired outcomes vs  Anti-patterns
*Desired outcomes:*
* Systems are stable, secure, and observable
* Operational metrics (not just help desk tickets) drive product decisions
* Feedback from support, telemetry, and users feeds back into the backlog
* Known issues are tracked, communicated, and improved
* The product roadmap evolves with usage, policy, and performance data

*Anti-patterns:*
* “BAU” seen as a holding pattern where nothing improves
* Reactive-only support with no root cause or trend analysis
* Incidents quietly resolved without learning or visibility
* Metrics that focus only on uptime, not usefulness or quality
* Support and ops disconnected from the product team


### When we do it
* From the moment the product enters production
* During early rollout and peak usage periods
* In response to incidents or user pain signals
* Continuously, as part of responsible product stewardship
* During transitions in policy, infrastructure, or user base


### Tools & Techniques
* Observability tooling (e.g. logging, metrics, traces)
* Real-time monitoring dashboards (e.g. Datadog, Azure Monitor, Prometheus)
* Uptime/performance alerts and SLO tracking
* Synthetic user testing and behavioural analytics
* Help desk ticketing systems and feedback portals
* Ops runbooks and incident response playbooks
* Security patching pipelines and vulnerability scanning
* Product health checks and regular “ops reviews”
* Data-informed backlog grooming (based on usage, not assumption)


### Practice in Action
**“After launch, the team created a dashboard showing user engagement, error rates, and service latency. When performance dipped on a key form, telemetry flagged the issue within minutes. The team traced it to a browser compatibility problem and issued a patch. User complaints dropped, and the ops team suggested design improvements for the next sprint.”**
— Cross-functional product team applying **Observability**, **Ops Reviews**, and **Feedback-Driven Iteration**
